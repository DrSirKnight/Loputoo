{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byGXdAYv85ix"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZaV4Vp5O5PF7",
        "outputId": "5bd409a8-a896-4b8f-d9d1-d6362308bad1"
      },
      "outputs": [],
      "source": [
        "!pip install estnltk==1.7.4\n",
        "\n",
        "from estnltk.wordnet import Wordnet\n",
        "wn = Wordnet()\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "from datetime import date, timedelta\n",
        "import random\n",
        "import numpy as np\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxgj2VPn8Zkg"
      },
      "source": [
        "# Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWVdqSrR78eC",
        "outputId": "74c230f4-bc45-4a3d-cba7-dbfebc0eb767"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/connections.json\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k_Nno0c8ifS"
      },
      "source": [
        "# Loading in word frequency. <br>\n",
        "\"Tasakaalus korpuse lemmad sageduse järjekorras\" can be obtained from [here](https://keeleressursid.ee/et/256-sagedusloendid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "ZTfoPjC44HAQ",
        "outputId": "b165020b-46a2-429f-cd35-f862d2b24c04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0d6616a7-68b3-4c0e-a392-933e48ad8f1e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0d6616a7-68b3-4c0e-a392-933e48ad8f1e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving lemma_kahanevas.txt to lemma_kahanevas.txt\n",
            "Total viable words found in common words list: 19684\n"
          ]
        }
      ],
      "source": [
        "uploaded = files.upload()\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "with open(file_name, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "rows = []\n",
        "for line in lines:\n",
        "    split = line.strip().split()\n",
        "    if len(split) >= 2:\n",
        "        freq = split[0]\n",
        "        sõna = split[1]\n",
        "        rows.append((freq, sõna))\n",
        "\n",
        "df = pd.DataFrame(rows, columns=[\"freq\", \"sõna\"])\n",
        "df[\"freq\"] = pd.to_numeric(df[\"freq\"], errors=\"coerce\")\n",
        "df = df.dropna(subset=[\"freq\"])\n",
        "\n",
        "n = 0\n",
        "common_words = []\n",
        "for synset in wn:\n",
        "  word_str = synset.name.split(\".\")[0]\n",
        "  if word_str in df[\"sõna\"].values and word_str not in common_words:\n",
        "    common_words += [word_str]\n",
        "    n += 1\n",
        "print(f\"Total viable words found in common words list: {n}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlMS8cU79BDN"
      },
      "source": [
        "# Generating connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz5xC5gD46A0"
      },
      "outputs": [],
      "source": [
        "# If one letter added to end of 2nd word\n",
        "def one_off(word1, word2):\n",
        "    return len(word2) == len(word1) + 1 and word2[:-1] == word1\n",
        "\n",
        "# Parts of words, such as car -> wheels\n",
        "def get_meronyms(word, synset):\n",
        "  meronyms = set()\n",
        "  for meronym in synset.meronyms:\n",
        "    meronyms.update(meronym.lemmas)\n",
        "  return meronyms\n",
        "\n",
        "# Holonyms - Unused for now\n",
        "def get_holonyms(synset):\n",
        "  holonyms = set()\n",
        "  for holonym in synset.holonyms:\n",
        "    h_lemmas = holonym.lemmas\n",
        "    for lemma in h_lemmas:\n",
        "      if word not in lemma:\n",
        "        holonyms.add(lemma)\n",
        "  return holonyms\n",
        "\n",
        "# Synonyms\n",
        "def get_lemmas(synset):\n",
        "  lemmas = set()\n",
        "  base_word = synset.lemmas[0].lower()\n",
        "\n",
        "  for lemma in synset.lemmas[1:]:\n",
        "    base_lemma = lemma.lower()\n",
        "    if base_word in base_lemma or base_lemma in base_word: # Remove some of the simpler ones, this does not account for everything, but that's intended\n",
        "      continue\n",
        "    lemmas.add(lemma)\n",
        "  return lemmas\n",
        "\n",
        "# Children of word\n",
        "def get_hyponyms(synset):\n",
        "  hyponyms = set()\n",
        "  all = synset.hyponyms\n",
        "  if len(all) <= 4:\n",
        "    all = synset.closure(\"hyponym\")\n",
        "  for hyponym in all:\n",
        "    hyponyms.add(hyponym.name.split(\".\")[0])\n",
        "  return hyponyms\n",
        "\n",
        "# Words with 1 letter added to it, such as puu -> puur\n",
        "def get_one_off(word, words):\n",
        "  one_offs = set()\n",
        "  for w in words:\n",
        "    if one_off(word, w) and w not in one_offs:\n",
        "      one_offs.add(w)\n",
        "  return one_offs\n",
        "\n",
        "def get_connections(word):\n",
        "    synsets = wn[word]\n",
        "    w_str = synsets[0].lemmas[0]\n",
        "    parts = []\n",
        "    synonyms = []\n",
        "    hyponyms = []\n",
        "    one_offs = []\n",
        "\n",
        "    all_word_connections = [] # Every possible connection to this word\n",
        "\n",
        "    for synset in synsets:\n",
        "      # Parts\n",
        "      syn_parts = list(get_meronyms(w_str, synset))\n",
        "      if len(syn_parts) >= 4:\n",
        "        parts.append(syn_parts)\n",
        "        all_word_connections += syn_parts\n",
        "\n",
        "      # Synonyms\n",
        "      lemmas = list(get_lemmas(synset))\n",
        "      if len(lemmas) >= 4:\n",
        "        synonyms.append(lemmas)\n",
        "        all_word_connections += lemmas\n",
        "\n",
        "      # Hyponyms\n",
        "      syn_hyponyms = list(get_hyponyms(synset))\n",
        "      if len(syn_hyponyms) >= 4:\n",
        "        hyponyms.append(syn_hyponyms)\n",
        "        all_word_connections += syn_hyponyms\n",
        "\n",
        "    # Words with 1 letter added at the end\n",
        "    one_offs_word = list(get_one_off(w_str, common_words))\n",
        "    if len(one_offs_word) >= 4:\n",
        "      one_offs.append(one_offs_word)\n",
        "      all_word_connections += one_offs_word\n",
        "\n",
        "    return w_str, synsets[0].definition, all_word_connections, parts, list(synonyms), list(hyponyms), list(one_offs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "t8pVGfIp72WV",
        "outputId": "74e61323-8996-4f47-9744-9e096d5de27e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/19684 words processed\n",
            "200/19684 words processed\n",
            "300/19684 words processed\n",
            "400/19684 words processed\n",
            "500/19684 words processed\n",
            "600/19684 words processed\n",
            "700/19684 words processed\n",
            "800/19684 words processed\n",
            "900/19684 words processed\n",
            "1000/19684 words processed\n",
            "1100/19684 words processed\n",
            "1200/19684 words processed\n",
            "1300/19684 words processed\n",
            "1400/19684 words processed\n",
            "1500/19684 words processed\n",
            "1600/19684 words processed\n",
            "1700/19684 words processed\n",
            "1800/19684 words processed\n",
            "1900/19684 words processed\n",
            "2000/19684 words processed\n",
            "2100/19684 words processed\n",
            "2200/19684 words processed\n",
            "2300/19684 words processed\n",
            "2400/19684 words processed\n",
            "2500/19684 words processed\n",
            "2600/19684 words processed\n",
            "2700/19684 words processed\n",
            "2800/19684 words processed\n",
            "2900/19684 words processed\n",
            "3000/19684 words processed\n",
            "3100/19684 words processed\n",
            "3200/19684 words processed\n",
            "3300/19684 words processed\n",
            "3400/19684 words processed\n",
            "3500/19684 words processed\n",
            "3600/19684 words processed\n",
            "3700/19684 words processed\n",
            "3800/19684 words processed\n",
            "3900/19684 words processed\n",
            "4000/19684 words processed\n",
            "4100/19684 words processed\n",
            "4200/19684 words processed\n",
            "4300/19684 words processed\n",
            "4400/19684 words processed\n",
            "4500/19684 words processed\n",
            "4600/19684 words processed\n",
            "4700/19684 words processed\n",
            "4800/19684 words processed\n",
            "4900/19684 words processed\n",
            "5000/19684 words processed\n",
            "5100/19684 words processed\n",
            "5200/19684 words processed\n",
            "5300/19684 words processed\n",
            "5400/19684 words processed\n",
            "5500/19684 words processed\n",
            "5600/19684 words processed\n",
            "5700/19684 words processed\n",
            "5800/19684 words processed\n",
            "5900/19684 words processed\n",
            "6000/19684 words processed\n",
            "6100/19684 words processed\n",
            "6200/19684 words processed\n",
            "6300/19684 words processed\n",
            "6400/19684 words processed\n",
            "6500/19684 words processed\n",
            "6600/19684 words processed\n",
            "6700/19684 words processed\n",
            "6800/19684 words processed\n",
            "6900/19684 words processed\n",
            "7000/19684 words processed\n",
            "7100/19684 words processed\n",
            "7200/19684 words processed\n",
            "7300/19684 words processed\n",
            "7400/19684 words processed\n",
            "7500/19684 words processed\n",
            "7600/19684 words processed\n",
            "7700/19684 words processed\n",
            "7800/19684 words processed\n",
            "7900/19684 words processed\n",
            "8000/19684 words processed\n",
            "8100/19684 words processed\n",
            "8200/19684 words processed\n",
            "8300/19684 words processed\n",
            "8400/19684 words processed\n",
            "8500/19684 words processed\n",
            "8600/19684 words processed\n",
            "8700/19684 words processed\n",
            "8800/19684 words processed\n",
            "8900/19684 words processed\n",
            "9000/19684 words processed\n",
            "9100/19684 words processed\n",
            "9200/19684 words processed\n",
            "9300/19684 words processed\n",
            "9400/19684 words processed\n",
            "9500/19684 words processed\n",
            "9600/19684 words processed\n",
            "9700/19684 words processed\n",
            "9800/19684 words processed\n",
            "9900/19684 words processed\n",
            "10000/19684 words processed\n",
            "10100/19684 words processed\n",
            "10200/19684 words processed\n",
            "10300/19684 words processed\n",
            "10400/19684 words processed\n",
            "10500/19684 words processed\n",
            "10600/19684 words processed\n",
            "10700/19684 words processed\n",
            "10800/19684 words processed\n",
            "10900/19684 words processed\n",
            "11000/19684 words processed\n",
            "11100/19684 words processed\n",
            "11200/19684 words processed\n",
            "11300/19684 words processed\n",
            "11400/19684 words processed\n",
            "11500/19684 words processed\n",
            "11600/19684 words processed\n",
            "11700/19684 words processed\n",
            "11800/19684 words processed\n",
            "11900/19684 words processed\n",
            "12000/19684 words processed\n",
            "12100/19684 words processed\n",
            "12200/19684 words processed\n",
            "12300/19684 words processed\n",
            "12400/19684 words processed\n",
            "12500/19684 words processed\n",
            "12600/19684 words processed\n",
            "12700/19684 words processed\n",
            "12800/19684 words processed\n",
            "12900/19684 words processed\n",
            "13000/19684 words processed\n",
            "13100/19684 words processed\n",
            "13200/19684 words processed\n",
            "13300/19684 words processed\n",
            "13400/19684 words processed\n",
            "13500/19684 words processed\n",
            "13600/19684 words processed\n",
            "13700/19684 words processed\n",
            "13800/19684 words processed\n",
            "13900/19684 words processed\n",
            "14000/19684 words processed\n",
            "14100/19684 words processed\n",
            "14200/19684 words processed\n",
            "14300/19684 words processed\n",
            "14400/19684 words processed\n",
            "14500/19684 words processed\n",
            "14600/19684 words processed\n",
            "14700/19684 words processed\n",
            "14800/19684 words processed\n",
            "14900/19684 words processed\n",
            "15000/19684 words processed\n",
            "15100/19684 words processed\n",
            "15200/19684 words processed\n",
            "15300/19684 words processed\n",
            "15400/19684 words processed\n",
            "15500/19684 words processed\n",
            "15600/19684 words processed\n",
            "15700/19684 words processed\n",
            "15800/19684 words processed\n",
            "15900/19684 words processed\n",
            "16000/19684 words processed\n",
            "16100/19684 words processed\n",
            "16200/19684 words processed\n",
            "16300/19684 words processed\n",
            "16400/19684 words processed\n",
            "16500/19684 words processed\n",
            "16600/19684 words processed\n",
            "16700/19684 words processed\n",
            "16800/19684 words processed\n",
            "16900/19684 words processed\n",
            "17000/19684 words processed\n",
            "17100/19684 words processed\n",
            "17200/19684 words processed\n",
            "17300/19684 words processed\n",
            "17400/19684 words processed\n",
            "17500/19684 words processed\n",
            "17600/19684 words processed\n",
            "17700/19684 words processed\n",
            "17800/19684 words processed\n",
            "17900/19684 words processed\n",
            "18000/19684 words processed\n",
            "18100/19684 words processed\n",
            "18200/19684 words processed\n",
            "18300/19684 words processed\n",
            "18400/19684 words processed\n",
            "18500/19684 words processed\n",
            "18600/19684 words processed\n",
            "18700/19684 words processed\n",
            "18800/19684 words processed\n",
            "18900/19684 words processed\n",
            "19000/19684 words processed\n",
            "19100/19684 words processed\n",
            "19200/19684 words processed\n",
            "19300/19684 words processed\n",
            "19400/19684 words processed\n",
            "19500/19684 words processed\n",
            "19600/19684 words processed\n",
            "19684/19684 words processed\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "max_words = len(common_words)\n",
        "\n",
        "all_connections = {}\n",
        "\n",
        "for word in common_words:\n",
        "  lemma, definition, all, parts, synonyms, hyponyms, one_offs = get_connections(word)\n",
        "\n",
        "  # Tracking progress\n",
        "  i += 1\n",
        "  if i % 100 == 0:\n",
        "    print(f\"{i}/{max_words} words processed\")\n",
        "\n",
        "  # Words with less than 4 connections are useless for the game\n",
        "  if len(all) < 4:\n",
        "    continue\n",
        "  all_connections[lemma] = [definition, all, parts, synonyms, hyponyms, one_offs]\n",
        "print(f\"{i}/{max_words} words processed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5NnUXadcRVP"
      },
      "source": [
        "# Load / Save generated connections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3AgKXtvAy_F"
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "with open(\"/content/drive/My Drive/connections.json\", \"w\") as file:\n",
        "    json.dump(all_connections, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoaYXF89BAAn"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open(\"/content/drive/My Drive/connections.json\", \"r\") as file:\n",
        "    all_connections = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NozV_MkBs2xw"
      },
      "source": [
        "# Data Display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "064arIkJlcQI"
      },
      "outputs": [],
      "source": [
        "def print_connections(all_connections, amount):\n",
        "  i = 0\n",
        "  for word, details in all_connections.items():\n",
        "    i += 1\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"  Definition: {details[0]}\")\n",
        "\n",
        "    print(f\"  Parts of: {details[2] if details[2] else 'None'}\")\n",
        "    print(f\"  Synonyms: {details[3] if details[3] else 'None'}\")\n",
        "    print(f\"  Children: {details[4] if details[4] else 'None'}\")\n",
        "    print(f\"  One-letter additions: {details[5] if details[5] else 'None'}\")\n",
        "\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"  Connections: {details[1] if details[1] else 'None'}\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    if i == amount:\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-MUnCXp4sZqR"
      },
      "outputs": [],
      "source": [
        "def print_connection(word, all_connections):\n",
        "  print(f\"Word: {word}\")\n",
        "  print(f\"  Definition: {all_connections[word][0]}\")\n",
        "  print(f\"  Parts of: {all_connections[word][2] if all_connections[word][2] else 'None'}\")\n",
        "  print(f\"  Synonyms: {all_connections[word][3] if all_connections[word][3] else 'None'}\")\n",
        "  print(f\"  Children: {all_connections[word][4] if all_connections[word][4] else 'None'}\")\n",
        "  print(f\"  One-letter additions: {all_connections[word][5] if all_connections[word][5] else 'None'}\")\n",
        "  print(\"=\" * 40)\n",
        "  print(f\"  Connections: {all_connections[word][1] if all_connections[word][1] else 'None'}\")\n",
        "  print(\"=\" * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm6_h59jsDSl",
        "outputId": "0b98fb09-94f6-4a47-80d6-96efbe936243"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: puu\n",
            "  Definition: pikaealine kõrgema tüvega puittaim\n",
            "  Parts of: None\n",
            "  Synonyms: None\n",
            "  Children: [['kruvipuu', 'viljapuu', 'säilik', 'nelgipuu', 'emalepp', 'kordaiit', 'heinpuu', 'kakao', 'rimu', 'guajakipuu', 'jalakapuu', 'ilang', 'jändrik', 'ahvileivapuu', 'leivapuu', 'mastipuu', 'jaanileivapuu', 'nöörpuu', 'pähklipuu', 'koola', 'sügamispuu', 'seemnepuu', 'põõsaspuu', 'mudelpuu', 'bonsai', 'teepuu', 'põlispuu', 'diospüür', 'kuivik', 'kaneelipuu', 'manglipuu', 'palm', 'võrapuu', 'kummipuu', 'vahtralehik', 'okaspuu', 'troopikapuu', 'spaleerpuu', 'meiud', 'pöök', 'eukalüpt', 'pargipuu', 'vormpuu', 'rosettpuu', 'ristipuu', 'plaatan', 'ilupuu', 'saar', 'kampripuu', 'miinuspuu', 'ajepuu', 'võrse', 'künnapuu', 'plusspuu', 'lehtpuu'], ['keelikas', 'toobripuu', 'kaust', 'kook', 'nott', 'ader', 'lasila', 'jalas', 'rõhtpuu', 'triikpuu', 'jugu', 'katlapuu'], ['pine', 'lapats', 'sugar', 'lõmm', 'noalõks'], ['saematerjal', 'korvipeerg', 'männipuit', 'laud', 'ajupuit', 'kogupuit', 'jalakas', 'kosk', 'toorpuit', 'ümarmaterjal', 'välisviimistluspuit', 'õunapuu', 'kadakapuit', 'grenadill', 'siseviimistluspuit', 'tõrvakas', 'kuusepuit', 'väärispuit', 'höövelmaterjal', 'töödeldud puit'], ['kataloogipuu', 'täispuu', 'kutsepuu', 'pinupuu', 'binaarpuu']]\n",
            "  One-letter additions: [['puud', 'puuk', 'puur', 'puus']]\n",
            "========================================\n",
            "  Connections: ['kruvipuu', 'viljapuu', 'säilik', 'nelgipuu', 'emalepp', 'kordaiit', 'heinpuu', 'kakao', 'rimu', 'guajakipuu', 'jalakapuu', 'ilang', 'jändrik', 'ahvileivapuu', 'leivapuu', 'mastipuu', 'jaanileivapuu', 'nöörpuu', 'pähklipuu', 'koola', 'sügamispuu', 'seemnepuu', 'põõsaspuu', 'mudelpuu', 'bonsai', 'teepuu', 'põlispuu', 'diospüür', 'kuivik', 'kaneelipuu', 'manglipuu', 'palm', 'võrapuu', 'kummipuu', 'vahtralehik', 'okaspuu', 'troopikapuu', 'spaleerpuu', 'meiud', 'pöök', 'eukalüpt', 'pargipuu', 'vormpuu', 'rosettpuu', 'ristipuu', 'plaatan', 'ilupuu', 'saar', 'kampripuu', 'miinuspuu', 'ajepuu', 'võrse', 'künnapuu', 'plusspuu', 'lehtpuu', 'keelikas', 'toobripuu', 'kaust', 'kook', 'nott', 'ader', 'lasila', 'jalas', 'rõhtpuu', 'triikpuu', 'jugu', 'katlapuu', 'pine', 'lapats', 'sugar', 'lõmm', 'noalõks', 'saematerjal', 'korvipeerg', 'männipuit', 'laud', 'ajupuit', 'kogupuit', 'jalakas', 'kosk', 'toorpuit', 'ümarmaterjal', 'välisviimistluspuit', 'õunapuu', 'kadakapuit', 'grenadill', 'siseviimistluspuit', 'tõrvakas', 'kuusepuit', 'väärispuit', 'höövelmaterjal', 'töödeldud puit', 'kataloogipuu', 'täispuu', 'kutsepuu', 'pinupuu', 'binaarpuu', 'puud', 'puuk', 'puur', 'puus']\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "print_connection(\"puu\", all_connections)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9_JagDEldN_",
        "outputId": "b27b1c16-8585-4903-b493-e20d13d1f712"
      },
      "outputs": [],
      "source": [
        "print_connections(all_connections, 500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snVmOGobtNyn"
      },
      "source": [
        "# Game Data Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STkOfHkgtsNi"
      },
      "source": [
        "Word Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "M62KZBUN5LWY",
        "outputId": "e44e8ed9-a220-448d-aa43-cf174623a7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/92212\n",
            "1001/92212\n",
            "2001/92212\n",
            "3001/92212\n",
            "4001/92212\n",
            "5001/92212\n",
            "6001/92212\n",
            "7001/92212\n",
            "8001/92212\n",
            "9001/92212\n",
            "10001/92212\n",
            "11001/92212\n",
            "12001/92212\n",
            "13001/92212\n",
            "14001/92212\n",
            "15001/92212\n",
            "16001/92212\n",
            "17001/92212\n",
            "18001/92212\n",
            "19001/92212\n",
            "20001/92212\n",
            "21001/92212\n",
            "22001/92212\n",
            "23001/92212\n",
            "24001/92212\n",
            "25001/92212\n",
            "26001/92212\n",
            "27001/92212\n",
            "28001/92212\n",
            "29001/92212\n",
            "30001/92212\n",
            "31001/92212\n",
            "32001/92212\n",
            "33001/92212\n",
            "34001/92212\n",
            "35001/92212\n",
            "36001/92212\n",
            "37001/92212\n",
            "38001/92212\n",
            "39001/92212\n",
            "40001/92212\n",
            "41001/92212\n",
            "42001/92212\n",
            "43001/92212\n",
            "44001/92212\n",
            "45001/92212\n",
            "46001/92212\n",
            "47001/92212\n",
            "48001/92212\n",
            "49001/92212\n",
            "50001/92212\n",
            "51001/92212\n",
            "52001/92212\n",
            "53001/92212\n",
            "54001/92212\n",
            "55001/92212\n",
            "56001/92212\n",
            "57001/92212\n",
            "58001/92212\n",
            "59001/92212\n",
            "60001/92212\n",
            "61001/92212\n",
            "62001/92212\n",
            "63001/92212\n",
            "64001/92212\n",
            "65001/92212\n",
            "66001/92212\n",
            "67001/92212\n",
            "68001/92212\n",
            "69001/92212\n",
            "70001/92212\n",
            "71001/92212\n",
            "72001/92212\n",
            "73001/92212\n",
            "74001/92212\n",
            "75001/92212\n",
            "76001/92212\n",
            "77001/92212\n",
            "78001/92212\n",
            "79001/92212\n",
            "80001/92212\n",
            "81001/92212\n",
            "82001/92212\n",
            "83001/92212\n",
            "84001/92212\n",
            "85001/92212\n",
            "86001/92212\n",
            "87001/92212\n",
            "88001/92212\n",
            "89001/92212\n",
            "90001/92212\n",
            "91001/92212\n",
            "92001/92212\n"
          ]
        }
      ],
      "source": [
        "word_defs = {}\n",
        "\n",
        "n = 0\n",
        "for word in wn:\n",
        "  n += 1\n",
        "total = n\n",
        "\n",
        "for i,word in enumerate(wn):\n",
        "  wdef = word.definition\n",
        "  wstr = word.name.split(\".\")[0]\n",
        "  word_defs[wstr] = wdef\n",
        "  if i % 1000 == 1:\n",
        "    print(f\"{i}/{total}\")\n",
        "\n",
        "with open(\"/content/drive/My Drive/definitions.json\", \"w\") as file:\n",
        "    json.dump(word_defs, file, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQD5ryO8lNR7"
      },
      "source": [
        "Puzzles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKTe3ahK8q-3"
      },
      "outputs": [],
      "source": [
        "class Puzzle:\n",
        "  def __init__(self, name, theme, difficulty, connections):\n",
        "    if len(connections) < 4:\n",
        "      raise ValueError(\"Puzzle must have at least 4 connections.\")\n",
        "    self.name = name\n",
        "    self.theme = theme\n",
        "    self.difficulty = difficulty\n",
        "    self.connections = connections\n",
        "\n",
        "  def get_name(self):\n",
        "    return self.name\n",
        "\n",
        "  def to_array(self):\n",
        "    return [self.name, self.theme, self.difficulty, self.connections]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mARu7nFC5HYv"
      },
      "source": [
        "Difficulty Calculation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCeduldA6paD"
      },
      "source": [
        "![Capture.PNG](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jRnIf8O4rBt"
      },
      "outputs": [],
      "source": [
        "maximum = 100\n",
        "minimum = df[\"freq\"].min()\n",
        "\n",
        "df[\"difficulty_mod\"] = np.where(\n",
        "    df[\"freq\"] > maximum,\n",
        "    1.0,\n",
        "    1.0 + (3.0 - 1.0) * (1 - (df[\"freq\"] - minimum) / (maximum - minimum)) # Provides a gradient value for difficulty\n",
        ")\n",
        "\n",
        "def get_diff_word(word, df):\n",
        "    el = df.loc[df[\"sõna\"] == word, \"difficulty_mod\"]\n",
        "    if el.empty:\n",
        "      return None\n",
        "    return el.values[0]\n",
        "\n",
        "# Finds if two words have 3 or more letters in common\n",
        "def closeness(word1, word2):\n",
        "    len1 = len(word1)\n",
        "    len2 = len(word2)\n",
        "\n",
        "    for i in range(len1):\n",
        "        for j in range(len2):\n",
        "            n = 0\n",
        "            while i + n < len1 and j + n < len2 and word1[i + n] == word2[j + n]:\n",
        "                n += 1\n",
        "                if n >= 3:\n",
        "                    return True\n",
        "    return False\n",
        "\n",
        "# Finds the difficulty of a puzzle\n",
        "def calc_difficulty(puzzle_type, words):\n",
        "  dif = 0\n",
        "  w_dif = 0\n",
        "\n",
        "  subword = False\n",
        "\n",
        "  for word in words:\n",
        "    if word in common_words:\n",
        "      w_dif = get_diff_word(word, df)\n",
        "    else: # If we can't find the word's difficulty we'll default to max\n",
        "      w_dif = 3\n",
        "    dif += w_dif\n",
        "\n",
        "    if puzzle_type == 4:\n",
        "      for word2 in words:\n",
        "        if closeness(word, word2):\n",
        "          subword = True\n",
        "          break\n",
        "  dif = dif / len(words)\n",
        "\n",
        "  match puzzle_type:\n",
        "    case 2: # Part of\n",
        "      return dif * 1.5\n",
        "    case 3: # Synonym\n",
        "      return dif\n",
        "    case 4: # Children\n",
        "      if subword:\n",
        "        return dif * 0.5\n",
        "      return dif * 2\n",
        "    case 5: # One-letter additions\n",
        "      return dif * 1.7\n",
        "  return dif"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOa6cz6Gu0q3"
      },
      "outputs": [],
      "source": [
        "def generate_puzzle(existing_puzzles, connections):\n",
        "  viable = False\n",
        "\n",
        "  while not viable and connections:\n",
        "    puzzle_choice = next(iter(connections))\n",
        "    puzzle_words = connections[puzzle_choice]\n",
        "\n",
        "    if any(puzzle_choice == existing_puzzle.get_name() for existing_puzzle in existing_puzzles):\n",
        "      connections.pop(puzzle_choice)\n",
        "      continue\n",
        "\n",
        "    if len(puzzle_words[1]) < 4:\n",
        "      connections.pop(puzzle_choice)\n",
        "      continue\n",
        "\n",
        "    valid_puzzle_types = set()\n",
        "\n",
        "    # Check all types of puzzles for length, 4 is minimum possible for a puzzle\n",
        "    for i in range(2,6):\n",
        "      for word_set in puzzle_words[i]:\n",
        "        if len(word_set) >= 4:\n",
        "          viable = True\n",
        "          valid_puzzle_types.add(i)\n",
        "    connections.pop(puzzle_choice)\n",
        "\n",
        "  if not viable: # No puzzles left\n",
        "    return None\n",
        "\n",
        "  found_puzzles = []\n",
        "  for puzzle_type in valid_puzzle_types:\n",
        "\n",
        "    match puzzle_type:\n",
        "      case 2: # Part of\n",
        "        puzzle_type_str = f\"{puzzle_choice} osa\"\n",
        "      case 3: # Synonym\n",
        "        puzzle_type_str = f\"{puzzle_choice} sünonüüm\"\n",
        "      case 4: # Children\n",
        "        puzzle_type_str = f\"{puzzle_choice} alamsõna\"\n",
        "      case 5: # One-letter additions\n",
        "        puzzle_type_str = f\"{puzzle_choice} ühe ekstra tähega\"\n",
        "\n",
        "    # Gets every possible combination for this type of puzzle\n",
        "    for synset_words in puzzle_words[puzzle_type]:\n",
        "      if len(synset_words) < 4:\n",
        "        continue\n",
        "      synset_list = list(synset_words)\n",
        "      if len(synset_list) > 8: # If we have too many variations puzzles are cut short to allow for more variety with sensible generation time\n",
        "        synset_list = synset_list[:8]\n",
        "\n",
        "      puzzles = itertools.combinations(synset_list, 4) # Get's all word combinations\n",
        "      for combo in puzzles:\n",
        "        puzzle_dif = calc_difficulty(puzzle_type, combo)\n",
        "        found_puzzles.append(Puzzle(puzzle_choice, puzzle_type_str, puzzle_dif, list(combo)))\n",
        "\n",
        "\n",
        "  return found_puzzles\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4rLv19UltUik",
        "outputId": "e97b0ef0-55ff-4446-d7ef-e9e362705766"
      },
      "outputs": [],
      "source": [
        "existing_puzzles = []\n",
        "i = 0\n",
        "\n",
        "while all_connections:\n",
        "  found_puzzles = generate_puzzle(existing_puzzles, all_connections)\n",
        "  if found_puzzles:\n",
        "    existing_puzzles += found_puzzles\n",
        "  i += 1\n",
        "  if i % 10 == 0:\n",
        "    print(f\"{len(all_connections)} puzzles left\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8UVZK36JhDg4"
      },
      "outputs": [],
      "source": [
        "jsonified_puzzles = []\n",
        "for puzzle in existing_puzzles:\n",
        "  jsonified_puzzles.append(puzzle.to_array())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w8ICIxKhF4S"
      },
      "outputs": [],
      "source": [
        "# Save\n",
        "with open(\"/content/drive/My Drive/puzzles.json\", \"w\") as file:\n",
        "    json.dump(jsonified_puzzles, file, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf_KR4LdaLd-"
      },
      "outputs": [],
      "source": [
        "# Load\n",
        "with open(\"/content/drive/My Drive/puzzles.json\", \"r\") as file:\n",
        "    jsonified_puzzles = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOAEjPRdZVh9",
        "outputId": "a178004a-3183-4002-a1b4-9e6b2fec70f5"
      },
      "outputs": [],
      "source": [
        "print(f\"{len(jsonified_puzzles)} puzzles generated.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NozV_MkBs2xw"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
